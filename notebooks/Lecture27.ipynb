{
 "metadata": {
  "name": "",
  "signature": "sha256:a7293bd223677b77f750f40c0b08778d3ba6270e9a700becd9300c0b8819c009"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Radial Basis Function Kernel or the Gaussian Kernel\n",
      "\\begin{equation}\n",
      "k({\\bf x},{\\bf x}') = exp\\left(-\\frac{1}{2\\sigma^2}||{\\bf x}-{\\bf x}'||^2\\right)\n",
      "\\end{equation}\n",
      "\n",
      "The parameter $\\sigma$ controls the width of the kernel as shown below."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn import linear_model as lm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x1 = 0\n",
      "sigma = 0.5\n",
      "x2 = np.linspace(-10,10,100)\n",
      "k = np.zeros((x2.shape[0],1))\n",
      "for sigma in [0.1,0.5,0.9,2]:\n",
      "    for i in range(k.shape[0]):\n",
      "        k[i] = exp(-0.5*sigma**2*((x1 - x2[i])**2));\n",
      "    plt.plot(x2,k,label='$\\sigma$='+str(sigma))\n",
      "plt.legend()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Demonstration of Kernel Methods"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### 1D Case\n",
      "First create a sample 1-D dataset which is not linearly separable"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.linspace(-10,10,21)\n",
      "y = np.zeros((X.shape[0],1))\n",
      "y[5:16] = 1\n",
      "plt.plot(X[np.where(y == 0)[0]],y[np.where(y == 0)[0]],'ro')\n",
      "plt.plot(X[np.where(y == 1)[0]],0*y[np.where(y == 1)[0]],'b+')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next map the data into a higher order space $X \\rightarrow X,X^2$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X1 = np.vstack((X,X**2)).transpose()\n",
      "plt.scatter(X1[np.where(y == 0)[0],0],X1[np.where(y == 0)[0],1],c='r',marker='o')\n",
      "plt.scatter(X1[np.where(y == 1)[0],0],X1[np.where(y == 1)[0],1],c='b',marker='+')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next find a linearly separable hyperplane in the new space"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.scatter(X1[np.where(y == 0)[0],0],X1[np.where(y == 0)[0],1],c='r',marker='o')\n",
      "plt.scatter(X1[np.where(y == 1)[0],0],X1[np.where(y == 1)[0],1],c='b',marker='+')\n",
      "plt.plot([-10,10],[30,30])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Map the higher dimensional hyperplane in the lower dimension"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(X[np.where(y == 0)[0]],y[np.where(y == 0)[0]],'ro')\n",
      "plt.plot(X[np.where(y == 1)[0]],0*y[np.where(y == 1)[0]],'b+')\n",
      "plt.plot(X,X**2-30)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 2D Case\n",
      "Let us consider the XOR data example"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sigma = np.array([[0.2,0],[0,0.2]])\n",
      "n = 8\n",
      "mu1 = np.array([1,1])\n",
      "mu2 = np.array([1,5])\n",
      "mu3 = np.array([5,1])\n",
      "mu4 = np.array([5,5])\n",
      "x11 = np.random.multivariate_normal(mu1,sigma,n)\n",
      "x15 = np.random.multivariate_normal(mu2,sigma,n)\n",
      "x51 = np.random.multivariate_normal(mu3,sigma,n)\n",
      "x55 = np.random.multivariate_normal(mu4,sigma,n)\n",
      "\n",
      "X = np.vstack([x11,x15,x51,x55])\n",
      "y = np.ones([4*n,1])\n",
      "y[n:3*n] = 2\n",
      "plt.scatter(X[np.where(y == 1)[0],0],X[np.where(y == 1)[0],1],c='r',marker='+')\n",
      "plt.scatter(X[np.where(y == 2)[0],0],X[np.where(y == 2)[0],1],c='b',marker='o')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Using logistic regression with polynomial basis function expansions\n",
      "While using higher order polynomials as the basis functions makes the boundary non-linear, it still is not able to capture the XOR distribution of the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Use logistic regression with basis function expansion\n",
      "p = 3\n",
      "mX = np.zeros((X.shape[0],p))\n",
      "for i in range(p):\n",
      "    mX[:,i] = np.sum(X**(i+1),axis=1)\n",
      "\n",
      "# Learn logistic regression\n",
      "lr = lm.LogisticRegression()\n",
      "w = lr.fit(mX,y.ravel())\n",
      "\n",
      "# evaluate on a grid\n",
      "x1 = np.linspace(-2,7,100)\n",
      "x2 = np.linspace(-2,7,100)\n",
      "xx1,xx2 = np.meshgrid(x1,x2)\n",
      "Xstar = np.zeros((x1.shape[0]*x2.shape[0],2))\n",
      "Xstar[:,0] = xx1.ravel()\n",
      "Xstar[:,1] = xx2.ravel()\n",
      "mXstar = np.zeros((Xstar.shape[0],p))\n",
      "for i in range(p):\n",
      "    mXstar[:,i] = np.sum(Xstar**(i+1),axis=1)\n",
      "ystar = lr.predict(mXstar)\n",
      "\n",
      "# visualize the result\n",
      "plt.contourf(x1,x2,ystar.reshape((x1.shape[0],x2.shape[0])),alpha=0.2)\n",
      "plt.scatter(X[np.where(y == 1)[0],0],X[np.where(y == 1)[0],1],c='r',marker='+')\n",
      "plt.scatter(X[np.where(y == 2)[0],0],X[np.where(y == 2)[0],1],c='b',marker='o')\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Using RBF kernel machine (network) \n",
      "The idea behind RBF network is to choose $k$ centroids and apply the Gaussian (RBF) kernel and each data point to transform it into a $k$ dimensional vector. \n",
      "\\begin{equation}\n",
      "{\\bf \\phi}({\\bf x}) = [k({\\bf x},{\\bf \\mu}_1),k({\\bf x},{\\bf \\mu}_2),\\ldots, k({\\bf x},{\\bf \\mu}_K)]\n",
      "\\end{equation}\n",
      "where the kernel is defined as:\n",
      "\\begin{equation}\n",
      "k({\\bf x},{\\bf \\mu}) = exp\\left(-\\frac{1}{2\\sigma^2}||{\\bf x}-{\\bf \\mu}||^2\\right)\n",
      "\\end{equation}"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define some means for RBF (here we can use the means of the above clusters)\n",
      "mus = np.vstack((mu1,mu2,mu3,mu4))\n",
      "sigma = 0.5\n",
      "# map the data into a 4D space using RBF kernel\n",
      "kX = np.zeros((X.shape[0],mus.shape[0]))\n",
      "for i in range(mus.shape[0]):\n",
      "    for j in range(X.shape[0]):\n",
      "        kX[j,i] = exp(-np.sum((X[j,:] - mus[i,:])**2)/sigma)\n",
      "    \n",
      "# Learn logistic regression\n",
      "lr = lm.LogisticRegression()\n",
      "w = lr.fit(kX,y.ravel())\n",
      "\n",
      "# evaluate on a grid\n",
      "x1 = np.linspace(-2,7,100)\n",
      "x2 = np.linspace(-2,7,100)\n",
      "xx1,xx2 = np.meshgrid(x1,x2)\n",
      "Xstar = np.zeros((x1.shape[0]*x2.shape[0],2))\n",
      "Xstar[:,0] = xx1.ravel()\n",
      "Xstar[:,1] = xx2.ravel()\n",
      "kXstar = np.zeros((Xstar.shape[0],mus.shape[0]))\n",
      "for i in range(mus.shape[0]):\n",
      "    for j in range(Xstar.shape[0]):\n",
      "        kXstar[j,i] = exp(-np.sum((Xstar[j,:] - mus[i,:])**2)/sigma)\n",
      "ystar = lr.predict(kXstar)\n",
      "\n",
      "# visualize the result\n",
      "plt.contourf(x1,x2,ystar.reshape((x1.shape[0],x2.shape[0])),alpha=0.2)\n",
      "plt.scatter(X[np.where(y == 1)[0],0],X[np.where(y == 1)[0],1],c='r',marker='+')\n",
      "plt.scatter(X[np.where(y == 2)[0],0],X[np.where(y == 2)[0],1],c='b',marker='o')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}